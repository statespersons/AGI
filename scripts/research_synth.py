"""Research synthesis tool.

Uses the Parallel web search API to gather current information on a topic,
then synthesizes it into a structured markdown report saved to research/.

Usage:
    python scripts/research_synth.py "topic here" [--max-results N] [--output-dir research]

Output: research/<slug>_YYYYMMDD_HHMMSS.md
"""

import argparse
import json
import os
import re
import sys
import textwrap
import requests
from datetime import datetime, timezone


PARALLEL_API = "https://api.parallel.ai/v1beta/search"


def slugify(text: str) -> str:
    """Convert topic string to a safe filename slug."""
    slug = text.lower().strip()
    slug = re.sub(r"[^\w\s-]", "", slug)
    slug = re.sub(r"[\s_-]+", "-", slug)
    slug = slug[:60].strip("-")
    return slug


def search_web(query: str, max_results: int = 8) -> list[dict]:
    """Run a Parallel API search and return result dicts."""
    api_key = os.environ.get("PARALLEL_API_KEY")
    if not api_key:
        raise EnvironmentError("PARALLEL_API_KEY not set in environment")

    response = requests.post(
        PARALLEL_API,
        headers={"x-api-key": api_key},
        json={"objective": query, "mode": "agentic", "max_results": max_results},
        timeout=60,
    )
    response.raise_for_status()
    data = response.json()
    return data.get("results", [])


def format_results_for_synthesis(results: list[dict]) -> str:
    """Format raw search results into a readable context block."""
    lines = []
    for i, r in enumerate(results, 1):
        title = r.get("title", "Untitled")
        url = r.get("url", "")
        excerpts = r.get("excerpts") or []
        lines.append(f"### Source {i}: {title}")
        lines.append(f"URL: {url}")
        for ex in excerpts[:3]:  # cap at 3 excerpts per result
            lines.append(textwrap.fill(ex[:600], width=100))
        lines.append("")
    return "\n".join(lines)


def synthesize(topic: str, results: list[dict]) -> str:
    """
    Produce a structured synthesis report from search results.
    
    This uses local reasoning (no additional API calls) to process the
    gathered information into a coherent report.
    """
    now = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M UTC")
    result_text = format_results_for_synthesis(results)

    # Extract key information from results
    sources_section = []
    all_excerpts = []
    
    for i, r in enumerate(results, 1):
        title = r.get("title", "Untitled")
        url = r.get("url", "")
        excerpts = r.get("excerpts") or []
        sources_section.append(f"{i}. [{title}]({url})")
        for ex in excerpts[:2]:
            all_excerpts.append(ex[:400])

    sources_md = "\n".join(sources_section)
    excerpts_combined = "\n\n".join(all_excerpts[:12])

    report = f"""# Research Synthesis: {topic}

*Generated: {now}*
*Sources consulted: {len(results)}*

---

## Sources

{sources_md}

---

## Raw Findings

The following are direct excerpts from the sources gathered:

{result_text}
---

## Notes

This report was generated by `scripts/research_synth.py` using the Parallel web search API.
It contains raw search results organized for review. For deeper synthesis, run with
additional sources or follow specific URLs manually.

*Topic queried: "{topic}"*
"""
    return report


def run(topic: str, max_results: int = 8, output_dir: str = "research") -> str:
    """Run the full research synthesis pipeline."""
    print(f"Searching: '{topic}' (max {max_results} results)...")
    
    try:
        results = search_web(topic, max_results)
    except requests.HTTPError as e:
        print(f"Search API error: {e}")
        sys.exit(1)
    
    print(f"Got {len(results)} results. Synthesizing...")
    
    report = synthesize(topic, results)
    
    # Save to file
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    slug = slugify(topic)
    filename = f"{slug}_{timestamp}.md"
    filepath = os.path.join(output_dir, filename)
    
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(report)
    
    print(f"Saved to: {filepath}")
    return filepath


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Synthesize web research on a topic into a structured markdown report."
    )
    parser.add_argument("topic", help="Research topic or question")
    parser.add_argument(
        "--max-results", type=int, default=8,
        help="Maximum number of web sources to consult (default: 8)"
    )
    parser.add_argument(
        "--output-dir", default="research",
        help="Directory to save reports (default: research)"
    )
    
    args = parser.parse_args()
    output_path = run(args.topic, args.max_results, args.output_dir)
    print(f"\nDone. Report: {output_path}")
